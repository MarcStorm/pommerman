\section{Discussion}
\label{sec:discussion}
It is evident from the literature that all the agents that do well have been trained for millions of times.\cite{rwightman} All tested setups showed the same sign of early convergence towards a single action. Our hypothesis is that longer training would yield more time for exploration in this giant search space and the agent might be able to take more meaningful actions.

Problems in learning to play could be because of the gap between an untrained agent and the actions needed to beat three simple agents is simply too large. That gab combined with the ever changing board and the randomness in the simple agents movement would create a giant search space and likely result in the agent never learning why it lost the game.






\paragraph{Reward function}

\paragraph{Lack of training}
% - Complexity
%   - It takes a lot of correct random actions to get a reward of 1 by killing the enemies
% - Exploration / Exploitation

\paragraph{Networks}