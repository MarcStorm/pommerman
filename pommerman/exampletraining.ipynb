{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "import environment as environment\n",
    "import neuralnet\n",
    "#from neuralnet import convolutional\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from util import flatten_state, flatten_state_not_first_board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set training and network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training settings\n",
    "trainingKwargs = {    \n",
    "    'num_episodes' : 100,\n",
    "    #rollout_limit = env.spec.timestep_limit # max rollout length\n",
    "    'discount_factor' : 0.9, # reward discount factor (gamma), 1.0 = no discount\n",
    "    'val_freq' : 25 # validation frequency\n",
    "}\n",
    "\n",
    "# training network settings\n",
    "netKwargs = {\n",
    "    'n_inputs' : 614,\n",
    "    'n_hidden' : 500,\n",
    "    #'n_outputs' : env.action_space.n, \n",
    "    'n_outputs' : 6, # This method is updated in the training class\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_norm' : False,\n",
    "    'conv1_in_channels' : 1,\n",
    "    'conv1_out_channels' : 3,\n",
    "    'conv2_out_channels' : 3,\n",
    "    'conv3_out_channels' : 3,\n",
    "    'kernel_size' : 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNet(nn.Module):\n",
    "    \"\"\"Policy network\"\"\"\n",
    "\n",
    "    def __init__(self, n_inputs, n_hidden, n_outputs, learning_rate, batch_norm, conv1_in_channels, conv1_out_channels, conv2_out_channels, conv3_out_channels, kernel_size):\n",
    "        super(PolicyNet, self).__init__()\n",
    "        # Network Parameters\n",
    "        # network\n",
    "        self.other_shape = [3]\n",
    "        \n",
    "        #Input for conv2d is (batch_size, num_channels, width, height)\n",
    "        self.conv1 = nn.Conv2d(in_channels = conv1_in_channels, out_channels=conv1_out_channels,\n",
    "                               kernel_size=kernel_size, stride=1, padding=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = conv1_out_channels, out_channels=conv2_out_channels,\n",
    "                               kernel_size=kernel_size, stride=1, padding=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = conv2_out_channels, out_channels=conv3_out_channels,\n",
    "                               kernel_size=kernel_size, stride=1, padding=2)\n",
    "        \n",
    "        self.convolution_out_size = 11*11*3\n",
    "        \n",
    "        self.ffn_input_size = n_inputs\n",
    "        \n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(n_inputs, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            #\n",
    "            nn.Dropout(0.25),\n",
    "            #nn.BatchNorm1d(n_hidden),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            #nn.BatchNorm1d(n_hidden),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            #nn.BatchNorm1d(n_hidden),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            #nn.BatchNorm1d(n_hidden),\n",
    "            nn.Linear(n_hidden, n_outputs),\n",
    "        )\n",
    "        \n",
    "        self.activation = F.relu\n",
    "        \n",
    "        if batch_norm:\n",
    "            self.bn1 = nn.BatchNorm2d(11)\n",
    "            #self.bn2 = nn.BatchNorm2d(num_channels)\n",
    "            #self.bn3 = nn.BatchNorm2d(num_channels)\n",
    "        else:\n",
    "            self.bn1 = lambda x: x\n",
    "            self.bn2 = lambda x: x\n",
    "            self.bn3 = lambda x: x\n",
    "        \n",
    "        self.ffn.apply(self.init_weights)\n",
    "        \n",
    "        #self.hidden = nn.Linear(n_inputs, n_hidden)\n",
    "        #self.hidden2 = nn.Linear(n_hidden, n_hidden)\n",
    "        #self.out = nn.Linear(n_hidden, n_outputs)\n",
    "        # training\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "       #Setup data for board\n",
    "        #print(x)\n",
    "        #print(x.keys())\n",
    "        board = x[0]['board']\n",
    "        \n",
    "        board = torch.tensor(board)\n",
    "        board = board.unsqueeze(0)\n",
    "        board = board.unsqueeze(0)\n",
    "        board = board.float()\n",
    "        for i in range(1,len(x)):\n",
    "            completeBoard = torch.tensor(x[i]['board'])\n",
    "            completeBoard = completeBoard.unsqueeze(0)\n",
    "            completeBoard = completeBoard.unsqueeze(0)\n",
    "            completeBoard = completeBoard.float()\n",
    "            board = torch.cat([board, completeBoard], dim=0)\n",
    "        \n",
    "        #print(board.size())\n",
    "        board = torch.autograd.Variable(board)\n",
    "        board = self.conv1(board)\n",
    "        board = self.bn1(board)\n",
    "        board = self.activation(board)\n",
    "        board = self.conv2(board)\n",
    "        board = self.bn1(board)\n",
    "        board = self.activation(board)\n",
    "        board = self.conv3(board)\n",
    "        board = self.bn1(board)\n",
    "        board = self.activation(board)\n",
    "        #print(board.size())\n",
    "        \n",
    "        #x = board.view(-1, self.l1_in_features)\n",
    "        x2 = board.view(-1, self.convolution_out_size)\n",
    "\n",
    "        x = flatten_state_not_first_board(x)\n",
    "        x = torch.cat([x2, x], dim=1)\n",
    "        \n",
    "        x = self.ffn(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "    \n",
    "    def loss(self, action_probabilities, returns):\n",
    "        return -torch.mean(torch.mul(torch.log(action_probabilities), returns))\n",
    "    \n",
    "    def init_weights(m, *args):\n",
    "        if type(m) == nn.Linear:\n",
    "            torch.nn.init.xavier_uniform(m.weight)\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instantiate environment, network, and trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neuralNet = PolicyNet(**netKwargs)\n",
    "env = environment.randomEnv() # could be stopEnv, simpleEnv All agents are same type\n",
    "#env = environment.manualEnv([\"si\", \"ra\", \"ra\"]) si = simple, st = stop, ra = random\n",
    "valueTrainer = train.PolicyTraining(env, neuralNet, **trainingKwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valueTrainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
